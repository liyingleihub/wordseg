新词发现sdk包，版本：0.0.1

此sdk包是无监督学习的新词发现程序，可发现词库以外的新词。
基础算法是目前通用的算法，但在此基础上，添加了三个新的辅助算法，进而大幅度提升了新词发现的准确率。

基础算法来自这篇文章，建议在使用此包之前先理解整体思想：
http://www.matrix67.com/blog/archives/5044

辅助算法包括：相邻词筛选，父子串筛选，词汇内部凝合度阶梯化，默认全部使用

数据的格式与要求：
如果是从多篇文章中发现新词，每篇文章要独立一行；如果仅有一篇文章也可以，单独一行即可。
进行json编码后才能作为数据使用，并将数据放入某个文件中，此文件中的内容即为要学习的数据。

目录与参数意义：
1、config目录，其中Config.php文件中定义了代码中需要用到的各种参数，通过修改各参数可对程序进行动态控制

参数取值会对结果产生较大影响：

词汇最大长度可自行设置，当前默认为6

单篇文章内的词频数默认为3，如果提高此值，可使准确度大幅提升，但召回率会快速下降

左右邻字信息熵阈值，默认为0.6，如果提高此值，可使准确度大幅提升，但召回率会快速下降

父子串筛选的参数，建议不动，如果理解算法，可以做适当调整

词汇内部凝合度的取值，我是根据文章数量在数千篇的量级，字数在百万级来设置的，在实际应用中
需要根据实际的文章数与字数来进行调整。

2、model目录，其中FenciModel.php文件中包含了程序需要用到的多个小模块，一般不需要进行调整。

3、src目录，包含主程序文件discovery.php，结巴的老词库dict.txt，学习的数据sample14.txt，
在使用此sdk时只需将数据放入此目录下，并修改config/Config.php中FILE_PATH_INPUT取值即可

4、test目录，运行test.php即可执行新词发现主程序，学习到的新词将被放入config/Config.php中FILE_PATH_OUTPUT
定义的文件中，默认是本目录下的new_dict.txt文件。
   new_dict.txt中有两列，第一列为发现的新词，第二列为该词在数据中出现的总次数。
   getcontent.php举例说明如何处理中文数据，将数据变为json格式，从而能够被学习。

其他注意点：

1、从数据中发现新词需要进行大量的计算，因此程序运行时间较长，举例中是1255篇文章，每篇平均1000字加，在8核服务器上
的运行时间大约需要10几分钟，随着数据量的增加，运行时间可能会超过数个小时

2、当数据量过大时，有可能导致程序的内存溢出，目前默认设置为1024m，可在config/Config.php中进行设置











